{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ICI0prX0vGz"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed\n",
        "from keras.layers import Embedding, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import brown\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Hl_vfRBjnseX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tiher5s9Vke-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51fe432-4f75-49a8-8739-6b7a8dc1210e"
      },
      "source": [
        "\n",
        "\n",
        "#Downloading Glove Word Embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-28 09:24:46--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-11-28 09:24:46--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-11-28 09:24:47--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 40s  \n",
            "\n",
            "2022-11-28 09:27:28 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bi9XCVnn27B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = codecs.open(\"corpus1.txt\", \"r\", encoding=\"utf8\")\n",
        "\n",
        "data = f.readlines()\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "o__7yjY2nvWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in range(len(data)):\n",
        "  if (data[i][0].strip()):\n",
        "    l.append(tuple(''.join(data[i]).split()))\n",
        "l[:10]\n",
        "len(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8LZCMQUrhe_",
        "outputId": "7cfd47f6-2e29-4535-b8f4-6357d5407969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4949"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4Ai_2xCKLJO"
      },
      "source": [
        "#separating sentences and tags as separate sequences\n",
        "sentences, sentence_tags =[], []\n",
        "for tagged_sentence in l:\n",
        "  if(len(tagged_sentence)<2):\n",
        "    print(tagged_sentence)\n",
        "  sentences.append(tagged_sentence[0])\n",
        "  sentence_tags.append(tagged_sentence[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlP9FpEL0ZV7"
      },
      "source": [
        "#Function to ignore the 0 padding while calculating accuracy\n",
        "def ignore_class_accuracy(to_ignore=0):\n",
        "    def ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        "\n",
        "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
        "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
        "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
        "        return accuracy\n",
        "    return ignore_accuracy\n",
        "\n",
        "#Function to return one code encoding of tags\n",
        "def one_hot_encoding(tag_sents, n_tags):\n",
        "    tag_one_hot_sent = []\n",
        "    for tag_sent in tag_sents:\n",
        "        tags_one_hot = []\n",
        "        for tag in tag_sent:\n",
        "            tags_one_hot.append(np.zeros(n_tags))\n",
        "            tags_one_hot[-1][tag] = 1.0\n",
        "        tag_one_hot_sent.append(tags_one_hot)\n",
        "    return np.array(tag_one_hot_sent)\n",
        "\n",
        "#Function to convert output into tags\n",
        "def logits_to_tags(tag_sentences, index):\n",
        "    tag_sequences = []\n",
        "    for tag_sentence in tag_sentences:\n",
        "        tag_sequence = []\n",
        "        for tag in tag_sentence:\n",
        "            # if index[np.argmax(tag)] == \"-PAD-\":\n",
        "            #     break\n",
        "            # else:\n",
        "                tag_sequence.append(index[np.argmax(tag)])\n",
        "        tag_sequences.append(np.array(tag_sequence))\n",
        "    return tag_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgfevJX3Vkfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf75560-5921-4466-e473-53942b59bfac"
      },
      "source": [
        "#Use the 300 dimensional GLove Word Embeddings\n",
        "glove_dir = './'\n",
        "\n",
        "embeddings_index = {} #initialize dictionary\n",
        "f = open('/content/glove.6B.300d.txt','rb')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ-t17BlVkft"
      },
      "source": [
        "acc = []\n",
        "conf_matrix = []\n",
        "precision_fold = []\n",
        "accuracy_fold = []\n",
        "recall_fold = []\n",
        "f1score_fold = []\n",
        "\n",
        "tag_list=['CC', 'DEM', 'DET', 'INJ', 'IRR', 'JJ', 'NN', 'NUM', 'PRP', 'PSP',\n",
        "       'QC', 'RB', 'SYM', 'UT', 'VM', 'WQ']\n",
        "\n",
        "# The integers for each tag are the same as above\n",
        "\n",
        "MAX_LENGTH = len(max(sentences, key=len)) # maximum words in a sentence\n",
        "\n",
        "conf_mat_df = pd.DataFrame(columns=tag_list, index=tag_list)\n",
        "conf_mat_df = conf_mat_df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt3WSLZuyPc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88264c0-daec-4670-c26b-ffc0f596af82"
      },
      "source": [
        "num_folds = 5\n",
        "iteration = 1\n",
        "kfold = KFold(num_folds)\n",
        "\n",
        "for train_index, test_index in kfold.split(range(len(data))):\n",
        "\n",
        "    print(\"Iteration \" + str(iteration) + \" started.\")\n",
        "    train_sentences = np.take(sentences,train_index).tolist()\n",
        "    test_sentences = np.take(sentences,test_index).tolist()\n",
        "    train_tags = np.take(sentence_tags,train_index).tolist()\n",
        "    test_tags = np.take(sentence_tags,test_index).tolist()\n",
        "\n",
        "    true_pos_tag = defaultdict(int)\n",
        "    false_pos_tag = defaultdict(int)\n",
        "    false_neg_tag = defaultdict(int)\n",
        "    precision_tags = defaultdict(float)\n",
        "    accuracy_tags = defaultdict(float)\n",
        "    recall_tags = defaultdict(float)\n",
        "    f1score_tags = defaultdict(float)\n",
        "\n",
        "    words, tags = set([]), set([])\n",
        "    #creating sets of words and tags\n",
        "    for sentence in train_sentences:\n",
        "        for word in sentence:\n",
        "            words.add(word.lower())\n",
        "\n",
        "    for tag_sent in train_tags:\n",
        "        for tag in tag_sent:\n",
        "            tags.add(tag)\n",
        "\n",
        "    #bulding vocabulary of words and tags\n",
        "    word2index = {word: i + 2 for i, word in enumerate(list(words))}\n",
        "    word2index['-PAD-'] = 0  # 0 is assigned for padding\n",
        "    word2index['-OOV-'] = 1  # 1 is assigned for unknown words\n",
        "    tag2index = {tag: i + 1 for i, tag in enumerate(list(tags))}\n",
        "    tag2index['-PAD-'] = 0  # 0 is assigned for padding\n",
        "\n",
        "    #Tokenising words and  by their indexes in vocabulary\n",
        "    train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
        "\n",
        "    for sentence in train_sentences:\n",
        "        sent_int = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                sent_int.append(word2index[word.lower()])\n",
        "            except KeyError:\n",
        "                sent_int.append(word2index['-OOV-'])\n",
        "        train_sentences_X.append(sent_int)\n",
        "\n",
        "    for sentence in test_sentences:\n",
        "        sent_int = []\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                sent_int.append(word2index[word.lower()])\n",
        "            except KeyError:\n",
        "                sent_int.append(word2index['-OOV-'])\n",
        "        test_sentences_X.append(sent_int)\n",
        "\n",
        "    for sent_tags in train_tags:\n",
        "        train_tags_y.append([tag2index[tag] for tag in sent_tags])\n",
        "\n",
        "    for sent_tags in test_tags:\n",
        "        test_tags_y.append([tag2index[tag] for tag in sent_tags])\n",
        "\n",
        "    #Add padding to sentences\n",
        "    train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "    test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "    train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "    test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "    #Building the Embedding Layer\n",
        "    embedding_dim = 300\n",
        "\n",
        "    embedding_matrix = np.zeros((len(word2index), embedding_dim))\n",
        "    for word, i in word2index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if i < len(word2index):\n",
        "            if embedding_vector is not None:\n",
        "                # Words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    #Building the BiLSTM model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "    model.add(Embedding(len(word2index), 300, weights=[embedding_matrix],trainable=False))\n",
        "    model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001),\n",
        "                  metrics=['accuracy', ignore_class_accuracy(0)])\n",
        "    model.summary()\n",
        "    one_hot_train_tags_y = one_hot_encoding(train_tags_y, len(tag2index))\n",
        "\n",
        "    #Training the model\n",
        "    history = model.fit(train_sentences_X, one_hot_encoding(train_tags_y, len(tag2index)),\n",
        "              batch_size=128, epochs= 9, validation_split=0.2)\n",
        "\n",
        "    scores = model.evaluate(test_sentences_X, one_hot_encoding(test_tags_y, len(tag2index)))\n",
        "    acc.append(scores[1]*100)\n",
        "\n",
        "\n",
        "    predictions = model.predict(test_sentences_X)\n",
        "    pred_sequence = logits_to_tags(predictions, {i: t for t, i in tag2index.items()})\n",
        "    y_prob_class = (model.predict(test_sentences_X, verbose = 1))>0.5\n",
        "    try:\n",
        "      for sen_num in range(len(test_tags)):\n",
        "          for i,tag in enumerate(test_tags[sen_num]):\n",
        "              conf_mat_df[tag][pred_sequence[sen_num][i]] +=1\n",
        "              if test_tags[sen_num][i] == pred_sequence[sen_num][i]:\n",
        "                true_pos_tag[tag] += 1\n",
        "              else:\n",
        "                false_neg_tag[tag] += 1\n",
        "                false_pos_tag[pred_sequence[sen_num][i]] += 1\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    for tag in tag_list[1:]:\n",
        "        precision_tags[tag] = true_pos_tag[tag] / (true_pos_tag[tag] + false_pos_tag[tag])\n",
        "        recall_tags[tag] = true_pos_tag[tag] / (true_pos_tag[tag] + false_neg_tag[tag])\n",
        "        f1score_tags[tag] = 2 * precision_tags[tag] * recall_tags[tag] / (precision_tags[tag] + recall_tags[tag])\n",
        "        accuracy_tags[tag] = true_pos_tag[tag] / (true_pos_tag[tag] + false_neg_tag[tag] + false_pos_tag[tag])\n",
        "\n",
        "    #conf_matrix.append(conf_mat_df)\n",
        "    accuracy_fold.append(accuracy_tags)\n",
        "    precision_fold.append(precision_tags)\n",
        "    recall_fold.append(recall_tags)\n",
        "    f1score_fold.append(f1score_tags)\n",
        "    if iteration == 1:\n",
        "        break\n",
        "    iteration += 1\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 started.\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 26, 300)           25200     \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirecti  (None, 26, 512)          1140736   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 26, 18)           9234      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 26, 18)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,175,170\n",
            "Trainable params: 1,149,970\n",
            "Non-trainable params: 25,200\n",
            "_________________________________________________________________\n",
            "Epoch 1/9\n",
            "25/25 [==============================] - 5s 65ms/step - loss: 1.2189 - accuracy: 0.9102 - ignore_accuracy: 0.0000e+00 - val_loss: 0.3263 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 2/9\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.2935 - accuracy: 0.9102 - ignore_accuracy: 0.0000e+00 - val_loss: 0.2727 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 3/9\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2654 - accuracy: 0.9102 - ignore_accuracy: 0.0000e+00 - val_loss: 0.2572 - val_accuracy: 0.9212 - val_ignore_accuracy: 0.3062\n",
            "Epoch 4/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2528 - accuracy: 0.9223 - ignore_accuracy: 0.3140 - val_loss: 0.2464 - val_accuracy: 0.9212 - val_ignore_accuracy: 0.3062\n",
            "Epoch 5/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2427 - accuracy: 0.9281 - ignore_accuracy: 0.3144 - val_loss: 0.2373 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 6/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2345 - accuracy: 0.9344 - ignore_accuracy: 0.3147 - val_loss: 0.2298 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 7/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2277 - accuracy: 0.9344 - ignore_accuracy: 0.3139 - val_loss: 0.2241 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 8/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2216 - accuracy: 0.9344 - ignore_accuracy: 0.3149 - val_loss: 0.2175 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 9/9\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2161 - accuracy: 0.9344 - ignore_accuracy: 0.3136 - val_loss: 0.2132 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.1900 - accuracy: 0.9522 - ignore_accuracy: 0.4857\n",
            "31/31 [==============================] - 1s 4ms/step\n",
            "31/31 [==============================] - 0s 4ms/step\n",
            "Iteration 1 started.\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 26, 300)           26100     \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirecti  (None, 26, 512)          1140736   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 26, 18)           9234      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 26, 18)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,176,070\n",
            "Trainable params: 1,149,970\n",
            "Non-trainable params: 26,100\n",
            "_________________________________________________________________\n",
            "Epoch 1/9\n",
            "25/25 [==============================] - 4s 51ms/step - loss: 1.1843 - accuracy: 0.9111 - ignore_accuracy: 0.0000e+00 - val_loss: 0.3150 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 2/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.9111 - ignore_accuracy: 0.0000e+00 - val_loss: 0.2732 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 3/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2610 - accuracy: 0.9164 - ignore_accuracy: 0.1404 - val_loss: 0.2589 - val_accuracy: 0.9212 - val_ignore_accuracy: 0.3062\n",
            "Epoch 4/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2486 - accuracy: 0.9248 - ignore_accuracy: 0.3556 - val_loss: 0.2473 - val_accuracy: 0.9212 - val_ignore_accuracy: 0.3062\n",
            "Epoch 5/9\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.2385 - accuracy: 0.9371 - ignore_accuracy: 0.3541 - val_loss: 0.2386 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 6/9\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.2302 - accuracy: 0.9383 - ignore_accuracy: 0.3536 - val_loss: 0.2310 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 7/9\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2232 - accuracy: 0.9383 - ignore_accuracy: 0.3542 - val_loss: 0.2241 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 8/9\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2169 - accuracy: 0.9383 - ignore_accuracy: 0.3527 - val_loss: 0.2181 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 9/9\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 0.2113 - accuracy: 0.9383 - ignore_accuracy: 0.3539 - val_loss: 0.2134 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2048 - accuracy: 0.9395 - ignore_accuracy: 0.3591\n",
            "31/31 [==============================] - 2s 7ms/step\n",
            "31/31 [==============================] - 0s 4ms/step\n",
            "Iteration 1 started.\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 26, 300)           28800     \n",
            "                                                                 \n",
            " bidirectional_12 (Bidirecti  (None, 26, 512)          1140736   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, 26, 18)           9234      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 26, 18)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,178,770\n",
            "Trainable params: 1,149,970\n",
            "Non-trainable params: 28,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/9\n",
            "25/25 [==============================] - 6s 53ms/step - loss: 1.1779 - accuracy: 0.9120 - ignore_accuracy: 0.0000e+00 - val_loss: 0.3153 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 2/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2804 - accuracy: 0.9120 - ignore_accuracy: 0.0000e+00 - val_loss: 0.2739 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 3/9\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 0.2550 - accuracy: 0.9188 - ignore_accuracy: 0.1791 - val_loss: 0.2596 - val_accuracy: 0.9212 - val_ignore_accuracy: 0.3062\n",
            "Epoch 4/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2428 - accuracy: 0.9287 - ignore_accuracy: 0.3793 - val_loss: 0.2492 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 5/9\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2329 - accuracy: 0.9410 - ignore_accuracy: 0.3778 - val_loss: 0.2400 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 6/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2248 - accuracy: 0.9410 - ignore_accuracy: 0.3772 - val_loss: 0.2320 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 7/9\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2179 - accuracy: 0.9410 - ignore_accuracy: 0.3780 - val_loss: 0.2260 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 8/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2116 - accuracy: 0.9410 - ignore_accuracy: 0.3778 - val_loss: 0.2206 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 9/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2062 - accuracy: 0.9410 - ignore_accuracy: 0.3777 - val_loss: 0.2137 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.2216 - accuracy: 0.9309 - ignore_accuracy: 0.2829\n",
            "31/31 [==============================] - 1s 4ms/step\n",
            "31/31 [==============================] - 0s 4ms/step\n",
            "Iteration 1 started.\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 26, 300)           28800     \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 26, 512)          1140736   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, 26, 18)           9234      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 26, 18)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,178,770\n",
            "Trainable params: 1,149,970\n",
            "Non-trainable params: 28,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/9\n",
            "25/25 [==============================] - 4s 50ms/step - loss: 1.1787 - accuracy: 0.9118 - ignore_accuracy: 0.0000e+00 - val_loss: 0.3158 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 2/9\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.2819 - accuracy: 0.9118 - ignore_accuracy: 0.0000e+00 - val_loss: 0.2750 - val_accuracy: 0.9100 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 3/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2578 - accuracy: 0.9193 - ignore_accuracy: 0.1962 - val_loss: 0.2601 - val_accuracy: 0.9212 - val_ignore_accuracy: 0.3062\n",
            "Epoch 4/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2457 - accuracy: 0.9262 - ignore_accuracy: 0.3734 - val_loss: 0.2495 - val_accuracy: 0.9212 - val_ignore_accuracy: 0.3062\n",
            "Epoch 5/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2356 - accuracy: 0.9398 - ignore_accuracy: 0.3705 - val_loss: 0.2405 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 6/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2273 - accuracy: 0.9403 - ignore_accuracy: 0.3708 - val_loss: 0.2330 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 7/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2202 - accuracy: 0.9403 - ignore_accuracy: 0.3704 - val_loss: 0.2258 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 8/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2140 - accuracy: 0.9403 - ignore_accuracy: 0.3695 - val_loss: 0.2194 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "Epoch 9/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2084 - accuracy: 0.9403 - ignore_accuracy: 0.3701 - val_loss: 0.2162 - val_accuracy: 0.9324 - val_ignore_accuracy: 0.3062\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.2176 - accuracy: 0.9330 - ignore_accuracy: 0.3052\n",
            "31/31 [==============================] - 1s 4ms/step\n",
            "31/31 [==============================] - 0s 4ms/step\n",
            "Iteration 1 started.\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 26, 300)           28800     \n",
            "                                                                 \n",
            " bidirectional_14 (Bidirecti  (None, 26, 512)          1140736   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 26, 18)           9234      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 26, 18)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,178,770\n",
            "Trainable params: 1,149,970\n",
            "Non-trainable params: 28,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/9\n",
            "25/25 [==============================] - 4s 52ms/step - loss: 1.1884 - accuracy: 0.9117 - ignore_accuracy: 0.0000e+00 - val_loss: 0.3181 - val_accuracy: 0.9099 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 2/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2845 - accuracy: 0.9117 - ignore_accuracy: 0.0000e+00 - val_loss: 0.2723 - val_accuracy: 0.9099 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 3/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2582 - accuracy: 0.9163 - ignore_accuracy: 0.1213 - val_loss: 0.2566 - val_accuracy: 0.9223 - val_ignore_accuracy: 0.3244\n",
            "Epoch 4/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.9259 - ignore_accuracy: 0.3696 - val_loss: 0.2456 - val_accuracy: 0.9348 - val_ignore_accuracy: 0.3250\n",
            "Epoch 5/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2354 - accuracy: 0.9399 - ignore_accuracy: 0.3664 - val_loss: 0.2366 - val_accuracy: 0.9348 - val_ignore_accuracy: 0.3250\n",
            "Epoch 6/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2271 - accuracy: 0.9399 - ignore_accuracy: 0.3666 - val_loss: 0.2291 - val_accuracy: 0.9348 - val_ignore_accuracy: 0.3250\n",
            "Epoch 7/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2199 - accuracy: 0.9399 - ignore_accuracy: 0.3667 - val_loss: 0.2228 - val_accuracy: 0.9348 - val_ignore_accuracy: 0.3250\n",
            "Epoch 8/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2136 - accuracy: 0.9399 - ignore_accuracy: 0.3659 - val_loss: 0.2162 - val_accuracy: 0.9348 - val_ignore_accuracy: 0.3250\n",
            "Epoch 9/9\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.2076 - accuracy: 0.9399 - ignore_accuracy: 0.3664 - val_loss: 0.2115 - val_accuracy: 0.9348 - val_ignore_accuracy: 0.3250\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.2146 - accuracy: 0.9324 - ignore_accuracy: 0.2920\n",
            "31/31 [==============================] - 1s 4ms/step\n",
            "31/31 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmojEjB4lmFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5b9a5a-103d-46bd-8a3e-02779fa8b7e1"
      },
      "source": [
        "predictions[0][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.1688215e-01, 5.6874678e-03, 8.4197540e-03, 6.2089264e-03,\n",
              "       2.4051750e-02, 5.1395368e-04, 5.0833328e-03, 2.1947069e-02,\n",
              "       3.2019755e-03, 4.8227571e-03, 6.8808859e-03, 1.1516171e-02,\n",
              "       1.2490945e-02, 5.6410879e-03, 6.2327515e-03, 6.3348472e-02,\n",
              "       2.9840809e-04, 1.9677216e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc8YP5VUVkf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfaae153-0e04-4917-88ab-de76a469dffc"
      },
      "source": [
        "tot_acc = np.mean(acc)\n",
        "tot_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74.00615970293681"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL4kLo4R2z-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14278b50-030b-4a52-a5ea-95df795b19a1"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[48.571908473968506,\n",
              " 35.9106183052063,\n",
              " 28.286290168762207,\n",
              " 30.517473816871643,\n",
              " 29.1973739862442,\n",
              " 95.21756172180176,\n",
              " 93.95493268966675,\n",
              " 93.0924654006958,\n",
              " 93.30225586891174,\n",
              " 93.23714971542358,\n",
              " 95.21756172180176,\n",
              " 93.95493268966675,\n",
              " 93.0924654006958,\n",
              " 93.30225586891174,\n",
              " 93.23714971542358]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['accuracy'])\n",
        "pyplot.title('model loss vs accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['loss', 'accuracy'], loc='upper right')\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NSXx9cQhmRnR",
        "outputId": "5d78d0b8-0d51-438b-fcb1-3cdfdeeb6fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}